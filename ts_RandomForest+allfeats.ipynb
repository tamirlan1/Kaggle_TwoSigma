{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest  + 'features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import cPickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "pd.options.display.max_columns = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df_original = pd.read_json('train.json')\n",
    "all_df = pd.read_csv('train_feats_max_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 83)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(all_df.drop(['interest_level'], 1),all_df[['interest_level']], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = cPickle.load(open('cat_feats.p', 'rb'))\n",
    "\n",
    "for col in ['interest_level']:\n",
    "    y_train[col] = y_train[col].astype('category')\n",
    "    y_val[col] = y_val[col].astype('category')\n",
    "    \n",
    "for col in cat_feats:\n",
    "    x_train[col] = x_train[col].astype('category')\n",
    "    x_val[col] = x_val[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [u'listing_id', 'index']\n",
    "x_train_small = x_train.drop(drop_list,1)\n",
    "\n",
    "x_val_small = x_val.drop(drop_list,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_small_nolon = x_train_small.drop(['longitude'], axis=1)\n",
    "# scores, pvalues = chi2(x_train_small_nolon, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_pvalues_cols = x_train_small_nolon.columns[(pvalues < 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_pvalues_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39481, 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low_pvalues_cols = cPickle.load(open('low_pvalues_cols.p', 'rb'))\n",
    "x_train_best = x_train_small#[low_pvalues_cols]\n",
    "x_val_best = x_val_small#[low_pvalues_cols]\n",
    "x_train_best.shape\n",
    "# x_train_best.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-9, 3, 13)\n",
    "# param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "# grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "# grid.fit(x_train_best[:10], y_train[:10])\n",
    "\n",
    "# print(\"The best parameters are %s with a score of %0.2f\"\n",
    "#       % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "# # Now we need to fit a classifier for all parameters in the 2d version\n",
    "# # (we use a smaller set of parameters here because it takes a while to train)\n",
    "\n",
    "# C_2d_range = [1e-2, 1, 1e2]\n",
    "# gamma_2d_range = [1e-1, 1, 1e1]\n",
    "# classifiers = []\n",
    "# for C in C_2d_range:\n",
    "#     for gamma in gamma_2d_range:\n",
    "#         clf = SVC(C=C, gamma=gamma)\n",
    "#         clf.fit(X_2d, y_2d)\n",
    "#         classifiers.append((C, gamma, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()#n_estimators=10, random_state=0)\n",
    "# parameters = {'max_features':[0.3, 0.5], 'max_depth':[10, 20], 'min_samples_split':[5, 10]}\n",
    "# clf = GridSearchCV(model, parameters, scoring='log_loss', cv=2)\n",
    "# # alphas = np.array([0.3,0.5])\n",
    "# # grid = GridSearchCV(estimator=model, param_grid=dict(max_features=alphas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit(x_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, max_features=0.5, max_depth=20, min_samples_split=20, random_state=0, n_jobs=-1)\n",
    "model = model.fit(x_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.891110</td>\n",
       "      <td>0.087416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.966434</td>\n",
       "      <td>0.031117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054558</td>\n",
       "      <td>0.571732</td>\n",
       "      <td>0.373710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083598</td>\n",
       "      <td>0.723263</td>\n",
       "      <td>0.193139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024353</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.110826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       high       low    medium\n",
       "0  0.021474  0.891110  0.087416\n",
       "1  0.002449  0.966434  0.031117\n",
       "2  0.054558  0.571732  0.373710\n",
       "3  0.083598  0.723263  0.193139\n",
       "4  0.024353  0.864821  0.110826"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_train = pd.DataFrame(model.predict_proba(x_train_best))\n",
    "# predicted = model.predict_proba(x)\n",
    "predicted_train.columns = ['high', 'low', 'medium']\n",
    "predicted_train.head()\n",
    "# predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40162879184380418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_train = log_loss(y_train, predicted_train.as_matrix())\n",
    "log_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063540</td>\n",
       "      <td>0.688537</td>\n",
       "      <td>0.247922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084760</td>\n",
       "      <td>0.545504</td>\n",
       "      <td>0.369736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010658</td>\n",
       "      <td>0.863525</td>\n",
       "      <td>0.125817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037549</td>\n",
       "      <td>0.785394</td>\n",
       "      <td>0.177057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.779291</td>\n",
       "      <td>0.187413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       high       low    medium\n",
       "0  0.063540  0.688537  0.247922\n",
       "1  0.084760  0.545504  0.369736\n",
       "2  0.010658  0.863525  0.125817\n",
       "3  0.037549  0.785394  0.177057\n",
       "4  0.033296  0.779291  0.187413"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_val = pd.DataFrame(model.predict_proba(x_val_best))\n",
    "# predicted = model.predict_proba(x)\n",
    "predicted_val.columns = ['high', 'low', 'medium']\n",
    "predicted_val.head()\n",
    "# predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60709048796069809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_val = log_loss(y_val, predicted_val.as_matrix())\n",
    "log_loss_val\n",
    "# 0.68867588674963398, 0.68 ok (n_estimators=20, max_features=0.5, max_depth=5, min_samples_split=2, random_state=0)\n",
    "# 0.65246470021282676, 0.60 ok (n_estimators=20, max_features=0.5, max_depth=5, min_samples_split=2, random_state=0)\n",
    "# 0.65992553205901083, 0.47953531208509781 OF (n_estimators=100, max_features='sqrt', max_depth=20, min_samples_split=2, random_state=0) \n",
    "# 0.64955018062340741, 0.5490683949104378 OF (n_estimators=100, max_features='sqrt', max_depth=20, min_samples_split=10, random_state=0)\n",
    "\n",
    "# new\n",
    "# best_loss: 0.627188125099\n",
    "# max_features: 0.3; max_depth: 20; min_samples_split: 20\n",
    "# 0.60709048796069809 (n_estimators=1000, max_features=0.5, max_depth=20, min_samples_split=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp = zip(x_train_best.columns, list(model.feature_importances_))\n",
    "# imp.sort(key = lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bad_feats = [i[0] for i in imp[-20:]]\n",
    "bad_feats = cPickle.load(open('bad_feats.p', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_best.drop(bad_feats, axis=1, inplace=True)\n",
    "x_val_best.drop(bad_feats, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39481, 60), (9871, 60))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_best.shape, x_val_best.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_loss(mf, md, mss):\n",
    "    kf = KFold(x_train_best.shape[0], n_folds=5, random_state=2017)\n",
    "    loss_tr = []\n",
    "    loss_ts = []\n",
    "    for train_index, test_index in kf:\n",
    "        x_tr = x_train_best.reset_index().loc[train_index].set_index(['index'])\n",
    "        y_tr =  y_train.reset_index().loc[train_index].set_index(['index'])\n",
    "        x_ts = x_train_best.reset_index().loc[test_index].set_index(['index'])\n",
    "        y_ts = y_train.reset_index().loc[test_index].set_index(['index'])\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=1000, max_features=mf, max_depth=md, min_samples_split=mss, random_state=23, n_jobs=-1)\n",
    "        model = model.fit(x_tr, y_tr)\n",
    "\n",
    "        predicted_ts = pd.DataFrame(model.predict_proba(x_ts))\n",
    "        predicted_ts.columns = ['high', 'low', 'medium']\n",
    "        log_loss_ts = log_loss(y_ts, predicted_ts.as_matrix())\n",
    "        loss_ts.append(log_loss_ts)\n",
    "    \n",
    "    print 'CV loss:', np.mean(loss_ts)\n",
    "    predicted_val = pd.DataFrame(model.predict_proba(x_val_best))\n",
    "    predicted_val.columns = ['high', 'low', 'medium']\n",
    "    log_loss_val = log_loss(y_val, predicted_val.as_matrix())\n",
    "    print 'Val loss:', log_loss_val\n",
    "    return np.mean(loss_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "max_features: 0.3; max_depth: 10; min_samples_split: 2\n",
      "50\n",
      "max_features: 0.3; max_depth: 10; min_samples_split: 5\n",
      "51\n",
      "max_features: 0.3; max_depth: 10; min_samples_split: 10\n",
      "52\n",
      "max_features: 0.3; max_depth: 10; min_samples_split: 20\n",
      "53\n",
      "max_features: 0.3; max_depth: 12; min_samples_split: 2\n",
      "54\n",
      "max_features: 0.3; max_depth: 12; min_samples_split: 5\n",
      "55\n",
      "max_features: 0.3; max_depth: 12; min_samples_split: 10\n",
      "56\n",
      "max_features: 0.3; max_depth: 12; min_samples_split: 20\n",
      "57\n",
      "max_features: 0.3; max_depth: 14; min_samples_split: 2\n",
      "58\n",
      "max_features: 0.3; max_depth: 14; min_samples_split: 5\n",
      "59\n",
      "max_features: 0.3; max_depth: 14; min_samples_split: 10\n",
      "60\n",
      "max_features: 0.3; max_depth: 14; min_samples_split: 20\n",
      "61\n",
      "max_features: 0.3; max_depth: 16; min_samples_split: 2\n",
      "CV loss: 0.615276730368\n",
      "Val loss: 0.616430655878\n",
      "62\n",
      "max_features: 0.3; max_depth: 16; min_samples_split: 5\n",
      "CV loss: 0.615071436554\n",
      "Val loss: 0.616783622836\n",
      "63\n",
      "max_features: 0.3; max_depth: 16; min_samples_split: 10\n",
      "CV loss: 0.615318231003\n",
      "Val loss: 0.616915093779\n",
      "64\n",
      "max_features: 0.3; max_depth: 16; min_samples_split: 20\n",
      "CV loss: 0.616888457313\n",
      "Val loss: 0.618006923444\n",
      "65\n",
      "max_features: 0.3; max_depth: 18; min_samples_split: 2\n",
      "CV loss: 0.613487081492\n",
      "Val loss: 0.614622061423\n",
      "66\n",
      "max_features: 0.3; max_depth: 18; min_samples_split: 5\n",
      "CV loss: 0.612433204837\n",
      "Val loss: 0.614012969857\n",
      "67\n",
      "max_features: 0.3; max_depth: 18; min_samples_split: 10\n",
      "CV loss: 0.612747626875\n",
      "Val loss: 0.614484114026\n",
      "68\n",
      "max_features: 0.3; max_depth: 18; min_samples_split: 20\n",
      "CV loss: 0.613964757339\n",
      "Val loss: 0.615840971201\n",
      "69\n",
      "max_features: 0.3; max_depth: 20; min_samples_split: 2\n",
      "CV loss: 0.614237891584\n",
      "Val loss: 0.61559072786\n",
      "70\n",
      "max_features: 0.3; max_depth: 20; min_samples_split: 5\n",
      "CV loss: 0.612227864207\n",
      "Val loss: 0.613487491233\n",
      "71\n",
      "max_features: 0.3; max_depth: 20; min_samples_split: 10\n",
      "CV loss: 0.611297560603\n",
      "Val loss: 0.612672312545\n",
      "72\n",
      "max_features: 0.3; max_depth: 20; min_samples_split: 20\n",
      "CV loss: 0.612580010383\n",
      "Val loss: 0.614586121393\n",
      "73\n",
      "max_features: 0.4; max_depth: 10; min_samples_split: 2\n",
      "CV loss: 0.634839382264\n",
      "Val loss: 0.636739147959\n",
      "74\n",
      "max_features: 0.4; max_depth: 10; min_samples_split: 5\n",
      "CV loss: 0.634845886372\n",
      "Val loss: 0.636565352659\n",
      "75\n",
      "max_features: 0.4; max_depth: 10; min_samples_split: 10\n",
      "CV loss: 0.635224944938\n",
      "Val loss: 0.636836721582\n",
      "76\n",
      "max_features: 0.4; max_depth: 10; min_samples_split: 20\n",
      "CV loss: 0.635509050114\n",
      "Val loss: 0.637385663828\n",
      "77\n",
      "max_features: 0.4; max_depth: 12; min_samples_split: 2\n",
      "CV loss: 0.622985609041\n",
      "Val loss: 0.624417580477\n",
      "78\n",
      "max_features: 0.4; max_depth: 12; min_samples_split: 5\n",
      "CV loss: 0.623067304252\n",
      "Val loss: 0.624554549881\n",
      "79\n",
      "max_features: 0.4; max_depth: 12; min_samples_split: 10\n",
      "CV loss: 0.62349729869\n",
      "Val loss: 0.624522131205\n",
      "80\n",
      "max_features: 0.4; max_depth: 12; min_samples_split: 20\n",
      "CV loss: 0.624205620819\n",
      "Val loss: 0.625647283092\n",
      "81\n",
      "max_features: 0.4; max_depth: 14; min_samples_split: 2\n",
      "CV loss: 0.615537455027\n",
      "Val loss: 0.617178108998\n",
      "82\n",
      "max_features: 0.4; max_depth: 14; min_samples_split: 5\n",
      "CV loss: 0.615641332651\n",
      "Val loss: 0.617120766968\n",
      "83\n",
      "max_features: 0.4; max_depth: 14; min_samples_split: 10\n",
      "CV loss: 0.615880774379\n",
      "Val loss: 0.617339129976\n",
      "84\n",
      "max_features: 0.4; max_depth: 14; min_samples_split: 20\n",
      "CV loss: 0.616735041061\n",
      "Val loss: 0.618318917504\n",
      "85\n",
      "max_features: 0.4; max_depth: 16; min_samples_split: 2\n",
      "CV loss: 0.612259199212\n",
      "Val loss: 0.612961041099\n",
      "86\n",
      "max_features: 0.4; max_depth: 16; min_samples_split: 5\n",
      "CV loss: 0.611605025205\n",
      "Val loss: 0.612978232507\n",
      "87\n",
      "max_features: 0.4; max_depth: 16; min_samples_split: 10\n",
      "CV loss: 0.611513625869\n",
      "Val loss: 0.613068552429\n",
      "88\n",
      "max_features: 0.4; max_depth: 16; min_samples_split: 20\n",
      "CV loss: 0.612785547935\n",
      "Val loss: 0.614216705511\n",
      "89\n",
      "max_features: 0.4; max_depth: 18; min_samples_split: 2\n",
      "CV loss: 0.612463922585\n",
      "Val loss: 0.613759182316\n",
      "90\n",
      "max_features: 0.4; max_depth: 18; min_samples_split: 5\n",
      "CV loss: 0.610668415639\n",
      "Val loss: 0.612265968751\n",
      "91\n",
      "max_features: 0.4; max_depth: 18; min_samples_split: 10\n",
      "CV loss: 0.610233724129\n",
      "Val loss: 0.611726156565\n",
      "92\n",
      "max_features: 0.4; max_depth: 18; min_samples_split: 20\n",
      "CV loss: 0.610607424016\n",
      "Val loss: 0.612512925814\n",
      "93\n",
      "max_features: 0.4; max_depth: 20; min_samples_split: 2\n",
      "CV loss: 0.614264302745\n",
      "Val loss: 0.61546092161\n",
      "94\n",
      "max_features: 0.4; max_depth: 20; min_samples_split: 5\n",
      "CV loss: 0.611408319874\n",
      "Val loss: 0.612427824826\n",
      "95\n",
      "max_features: 0.4; max_depth: 20; min_samples_split: 10\n",
      "CV loss: 0.609532540195\n",
      "Val loss: 0.611413030072\n",
      "96\n",
      "max_features: 0.4; max_depth: 20; min_samples_split: 20\n",
      "CV loss: 0.609852966333\n",
      "Val loss: 0.6113763362\n",
      "97\n",
      "max_features: 0.5; max_depth: 10; min_samples_split: 2\n",
      "CV loss: 0.630622430407\n",
      "Val loss: 0.632137653445\n",
      "98\n",
      "max_features: 0.5; max_depth: 10; min_samples_split: 5\n",
      "CV loss: 0.63075537621\n",
      "Val loss: 0.632189733609\n",
      "99\n",
      "max_features: 0.5; max_depth: 10; min_samples_split: 10\n",
      "CV loss: 0.630902610426\n",
      "Val loss: 0.632586497837\n",
      "100\n",
      "max_features: 0.5; max_depth: 10; min_samples_split: 20\n",
      "CV loss: 0.631326763419\n",
      "Val loss: 0.632940339399\n",
      "101\n",
      "max_features: 0.5; max_depth: 12; min_samples_split: 2\n",
      "CV loss: 0.619875424215\n",
      "Val loss: 0.620820963196\n",
      "102\n",
      "max_features: 0.5; max_depth: 12; min_samples_split: 5\n",
      "CV loss: 0.619731417908\n",
      "Val loss: 0.621366163435\n",
      "103\n",
      "max_features: 0.5; max_depth: 12; min_samples_split: 10\n",
      "CV loss: 0.620053026592\n",
      "Val loss: 0.621495464371\n",
      "104\n",
      "max_features: 0.5; max_depth: 12; min_samples_split: 20\n",
      "CV loss: 0.620671410888\n",
      "Val loss: 0.622121822755\n",
      "105\n",
      "max_features: 0.5; max_depth: 14; min_samples_split: 2\n",
      "CV loss: 0.613838605664\n",
      "Val loss: 0.615015497153\n",
      "106\n",
      "max_features: 0.5; max_depth: 14; min_samples_split: 5\n",
      "CV loss: 0.613330633713\n",
      "Val loss: 0.615121908318\n",
      "107\n",
      "max_features: 0.5; max_depth: 14; min_samples_split: 10\n",
      "CV loss: 0.613361834124\n",
      "Val loss: 0.615590048933\n",
      "108\n",
      "max_features: 0.5; max_depth: 14; min_samples_split: 20\n",
      "CV loss: 0.614327327451\n",
      "Val loss: 0.616202290059\n",
      "109\n",
      "max_features: 0.5; max_depth: 16; min_samples_split: 2\n",
      "CV loss: 0.611637247377\n",
      "Val loss: 0.613238820159\n",
      "110\n",
      "max_features: 0.5; max_depth: 16; min_samples_split: 5\n",
      "CV loss: 0.610704416892\n",
      "Val loss: 0.612661097403\n",
      "111\n",
      "max_features: 0.5; max_depth: 16; min_samples_split: 10\n",
      "CV loss: 0.610326331377\n",
      "Val loss: 0.611990810454\n",
      "112\n",
      "max_features: 0.5; max_depth: 16; min_samples_split: 20\n",
      "CV loss: 0.611109878489\n",
      "Val loss: 0.612751042912\n",
      "113\n",
      "max_features: 0.5; max_depth: 18; min_samples_split: 2\n",
      "CV loss: 0.612835914641\n",
      "Val loss: 0.614427973875\n",
      "114\n",
      "max_features: 0.5; max_depth: 18; min_samples_split: 5\n",
      "CV loss: 0.610709289893\n",
      "Val loss: 0.612227496761\n",
      "115\n",
      "max_features: 0.5; max_depth: 18; min_samples_split: 10\n",
      "CV loss: 0.609536306181\n",
      "Val loss: 0.611630810892\n",
      "116\n",
      "max_features: 0.5; max_depth: 18; min_samples_split: 20\n",
      "CV loss: 0.609537677816\n",
      "Val loss: 0.611557872741\n",
      "117\n",
      "max_features: 0.5; max_depth: 20; min_samples_split: 2\n",
      "CV loss: 0.616836187852\n",
      "Val loss: 0.616770721339\n",
      "118\n",
      "max_features: 0.5; max_depth: 20; min_samples_split: 5\n",
      "CV loss: 0.612053024171\n",
      "Val loss: 0.613658181033\n",
      "119\n",
      "max_features: 0.5; max_depth: 20; min_samples_split: 10\n",
      "CV loss: 0.609948666448\n",
      "Val loss: 0.611489121076\n",
      "120\n",
      "max_features: 0.5; max_depth: 20; min_samples_split: 20\n",
      "CV loss: 0.609156404808\n",
      "Val loss: 0.611700846373\n",
      "best_loss: 0.609156404808\n",
      "best_params: max_features: 0.5; max_depth: 20; min_samples_split: 20\n"
     ]
    }
   ],
   "source": [
    "max_features = [0.3, 0.4, 0.5] #'sqrt',0.2, \n",
    "max_depth = [10, 12, 14, 16, 18, 20]\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "best_loss = 100\n",
    "best_params = ''\n",
    "count = 49\n",
    "for mf in max_features:\n",
    "    for md in max_depth:\n",
    "        for mss in min_samples_split:\n",
    "            print count\n",
    "            count += 1\n",
    "            params = 'max_features: ' + str(mf) + '; max_depth: ' + str(md) + '; min_samples_split: ' + str(mss)\n",
    "            print params\n",
    "            if mf == 0.3:\n",
    "                if md in (10, 12, 14):\n",
    "                    continue\n",
    "\n",
    "#             model = RandomForestClassifier(n_estimators=500, max_features=mf, max_depth=md, min_samples_split=mss, random_state=0)\n",
    "#             model = model.fit(x_train_best, y_train)\n",
    "#             predicted_train = pd.DataFrame(model.predict_proba(x_train_best))\n",
    "#             predicted_train.columns = ['high', 'low', 'medium']\n",
    "#             log_loss_train = log_loss(y_train, predicted_train.as_matrix())\n",
    "#             print 'Train loss:', log_loss_train\n",
    "#             predicted_val = pd.DataFrame(model.predict_proba(x_val_best))\n",
    "#             predicted_val.columns = ['high', 'low', 'medium']\n",
    "#             log_loss_val = log_loss(y_val, predicted_val.as_matrix())\n",
    "#             print 'Val loss:', log_loss_val\n",
    "#             if log_loss_val < best_loss:\n",
    "#                 best_loss = log_loss_val\n",
    "#                 best_params = params\n",
    "            cv_loss = get_cv_loss(mf, md, mss)\n",
    "            if cv_loss < best_loss:\n",
    "                best_loss = cv_loss\n",
    "                best_params = params   \n",
    "                \n",
    "print 'best_loss:', best_loss\n",
    "print 'best_params:', best_params\n",
    "# best_loss: 0.638016960424\n",
    "# best_params: max_features: 0.3; max_depth: 18; min_samples_split: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "## Competition Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_feats_max_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>created</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>elevator</th>\n",
       "      <th>hardwood floors</th>\n",
       "      <th>doorman</th>\n",
       "      <th>dishwasher</th>\n",
       "      <th>laundry in building</th>\n",
       "      <th>no fee</th>\n",
       "      <th>fitness center</th>\n",
       "      <th>pre-war</th>\n",
       "      <th>roof deck</th>\n",
       "      <th>outdoor space</th>\n",
       "      <th>dining room</th>\n",
       "      <th>high speed internet</th>\n",
       "      <th>balcony</th>\n",
       "      <th>swimming pool</th>\n",
       "      <th>new construction</th>\n",
       "      <th>terrace</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>loft</th>\n",
       "      <th>garden/patio</th>\n",
       "      <th>wheelchair access</th>\n",
       "      <th>fireplace</th>\n",
       "      <th>simplex</th>\n",
       "      <th>lowrise</th>\n",
       "      <th>garage</th>\n",
       "      <th>reduced fee</th>\n",
       "      <th>furnished</th>\n",
       "      <th>multi-level</th>\n",
       "      <th>high ceilings</th>\n",
       "      <th>private outdoor space</th>\n",
       "      <th>parking space</th>\n",
       "      <th>live in super</th>\n",
       "      <th>renovated</th>\n",
       "      <th>green building</th>\n",
       "      <th>storage</th>\n",
       "      <th>stainless steel appliances</th>\n",
       "      <th>light</th>\n",
       "      <th>granite kitchen</th>\n",
       "      <th>bike room</th>\n",
       "      <th>exposed brick</th>\n",
       "      <th>marble bath</th>\n",
       "      <th>pets on approval</th>\n",
       "      <th>walk in closet(s)</th>\n",
       "      <th>valet</th>\n",
       "      <th>subway</th>\n",
       "      <th>residents lounge</th>\n",
       "      <th>highrise</th>\n",
       "      <th>short term allowed</th>\n",
       "      <th>childrens playroom</th>\n",
       "      <th>no pets</th>\n",
       "      <th>duplex</th>\n",
       "      <th>actual apt. photos</th>\n",
       "      <th>central a/c</th>\n",
       "      <th>view</th>\n",
       "      <th>live/work</th>\n",
       "      <th>virtual doorman</th>\n",
       "      <th>sauna</th>\n",
       "      <th>microwave</th>\n",
       "      <th>shares ok</th>\n",
       "      <th>post-war</th>\n",
       "      <th>brownstone</th>\n",
       "      <th>business center</th>\n",
       "      <th>sublet</th>\n",
       "      <th>midrise</th>\n",
       "      <th>pet friendly</th>\n",
       "      <th>guarantors accepted</th>\n",
       "      <th>attended lobby</th>\n",
       "      <th>package room</th>\n",
       "      <th>video intercom</th>\n",
       "      <th>community recreation facilities</th>\n",
       "      <th>skylight</th>\n",
       "      <th>flex-2</th>\n",
       "      <th>cable/satellite tv</th>\n",
       "      <th>all utilities included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.465623e+09</td>\n",
       "      <td>40.7185</td>\n",
       "      <td>7142618</td>\n",
       "      <td>-73.9865</td>\n",
       "      <td>2950</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.466750e+09</td>\n",
       "      <td>40.7278</td>\n",
       "      <td>7210040</td>\n",
       "      <td>-74.0000</td>\n",
       "      <td>2850</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  bathrooms  bedrooms       created  latitude  listing_id  longitude  \\\n",
       "0      0        1.0         1  1.465623e+09   40.7185     7142618   -73.9865   \n",
       "1      1        1.0         2  1.466750e+09   40.7278     7210040   -74.0000   \n",
       "\n",
       "   price  num_photos  elevator  hardwood floors  doorman  dishwasher  \\\n",
       "0   2950           8         1                1        0           1   \n",
       "1   2850           3         0                1        0           0   \n",
       "\n",
       "   laundry in building  no fee  fitness center  pre-war  roof deck  \\\n",
       "0                    1       0               0        0          0   \n",
       "1                    0       0               0        1          0   \n",
       "\n",
       "   outdoor space  dining room  high speed internet  balcony  swimming pool  \\\n",
       "0              1            0                    0        0              0   \n",
       "1              0            0                    0        0              0   \n",
       "\n",
       "   new construction  terrace  exclusive  loft  garden/patio  \\\n",
       "0                 0        1          0     0             0   \n",
       "1                 0        0          0     0             0   \n",
       "\n",
       "   wheelchair access  fireplace  simplex  lowrise  garage  reduced fee  \\\n",
       "0                  0          0        0        0       0            0   \n",
       "1                  0          0        0        0       0            0   \n",
       "\n",
       "   furnished  multi-level  high ceilings  private outdoor space  \\\n",
       "0          0            0              0                      0   \n",
       "1          0            0              0                      0   \n",
       "\n",
       "   parking space  live in super  renovated  green building  storage  \\\n",
       "0              0              0          1               0        1   \n",
       "1              0              0          1               0        0   \n",
       "\n",
       "   stainless steel appliances  light  granite kitchen  bike room  \\\n",
       "0                           0      0                0          0   \n",
       "1                           1      0                0          0   \n",
       "\n",
       "   exposed brick  marble bath  pets on approval  walk in closet(s)  valet  \\\n",
       "0              0            0                 0                  0      0   \n",
       "1              0            1                 0                  0      0   \n",
       "\n",
       "   subway  residents lounge  highrise  short term allowed  childrens playroom  \\\n",
       "0       1                 0         0                   0                   0   \n",
       "1       0                 0         0                   0                   0   \n",
       "\n",
       "   no pets  duplex  actual apt. photos  central a/c  view  live/work  \\\n",
       "0        0       0                   0            0     0          0   \n",
       "1        0       0                   0            0     1          0   \n",
       "\n",
       "   virtual doorman  sauna  microwave  shares ok  post-war  brownstone  \\\n",
       "0                0      0          0          0         0           0   \n",
       "1                0      0          0          0         0           0   \n",
       "\n",
       "   business center  sublet  midrise  pet friendly  guarantors accepted  \\\n",
       "0                0       0        0             0                    0   \n",
       "1                0       0        0             1                    0   \n",
       "\n",
       "   attended lobby  package room  video intercom  \\\n",
       "0               0             0               0   \n",
       "1               0             0               0   \n",
       "\n",
       "   community recreation facilities  skylight  flex-2  cable/satellite tv  \\\n",
       "0                                0         0       0                   0   \n",
       "1                                0         0       0                   0   \n",
       "\n",
       "   all utilities included  \n",
       "0                       0  \n",
       "1                       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 60)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test_df[x_train_best.columns]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.711241</td>\n",
       "      <td>0.263924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.257538</td>\n",
       "      <td>0.342242</td>\n",
       "      <td>0.400220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015254</td>\n",
       "      <td>0.897701</td>\n",
       "      <td>0.087045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031330</td>\n",
       "      <td>0.616620</td>\n",
       "      <td>0.352050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022746</td>\n",
       "      <td>0.744181</td>\n",
       "      <td>0.233073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       high       low    medium\n",
       "0  0.024834  0.711241  0.263924\n",
       "1  0.257538  0.342242  0.400220\n",
       "2  0.015254  0.897701  0.087045\n",
       "3  0.031330  0.616620  0.352050\n",
       "4  0.022746  0.744181  0.233073"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_x = pd.DataFrame(model.predict_proba(x_test))\n",
    "pred_x.columns = ['high', 'low', 'medium']\n",
    "pred_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.merge(test_df[['listing_id']].reset_index(), pred_x.reset_index(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = subm[['listing_id', 'high', 'medium', 'low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.shape\n",
    "# (74659, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv('Submission_RandomForest_auto120_tune+60feats_desc.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features=0.3, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=1, oob_score=False, random_state=21,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
