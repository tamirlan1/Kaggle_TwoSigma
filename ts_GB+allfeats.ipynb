{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting  + 'features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import cPickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from time import time\n",
    "\n",
    "pd.options.display.max_columns = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_df = pd.read_json('train.json')\n",
    "all_df = pd.read_csv('train_feats_max_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 83)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>created</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>elevator</th>\n",
       "      <th>hardwood floors</th>\n",
       "      <th>doorman</th>\n",
       "      <th>dishwasher</th>\n",
       "      <th>laundry in building</th>\n",
       "      <th>no fee</th>\n",
       "      <th>fitness center</th>\n",
       "      <th>pre-war</th>\n",
       "      <th>roof deck</th>\n",
       "      <th>outdoor space</th>\n",
       "      <th>dining room</th>\n",
       "      <th>high speed internet</th>\n",
       "      <th>balcony</th>\n",
       "      <th>swimming pool</th>\n",
       "      <th>new construction</th>\n",
       "      <th>terrace</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>loft</th>\n",
       "      <th>garden/patio</th>\n",
       "      <th>wheelchair access</th>\n",
       "      <th>fireplace</th>\n",
       "      <th>simplex</th>\n",
       "      <th>lowrise</th>\n",
       "      <th>garage</th>\n",
       "      <th>reduced fee</th>\n",
       "      <th>furnished</th>\n",
       "      <th>multi-level</th>\n",
       "      <th>high ceilings</th>\n",
       "      <th>private outdoor space</th>\n",
       "      <th>parking space</th>\n",
       "      <th>live in super</th>\n",
       "      <th>renovated</th>\n",
       "      <th>green building</th>\n",
       "      <th>storage</th>\n",
       "      <th>stainless steel appliances</th>\n",
       "      <th>light</th>\n",
       "      <th>granite kitchen</th>\n",
       "      <th>bike room</th>\n",
       "      <th>exposed brick</th>\n",
       "      <th>marble bath</th>\n",
       "      <th>pets on approval</th>\n",
       "      <th>walk in closet(s)</th>\n",
       "      <th>valet</th>\n",
       "      <th>subway</th>\n",
       "      <th>residents lounge</th>\n",
       "      <th>highrise</th>\n",
       "      <th>short term allowed</th>\n",
       "      <th>childrens playroom</th>\n",
       "      <th>no pets</th>\n",
       "      <th>duplex</th>\n",
       "      <th>actual apt. photos</th>\n",
       "      <th>central a/c</th>\n",
       "      <th>view</th>\n",
       "      <th>live/work</th>\n",
       "      <th>virtual doorman</th>\n",
       "      <th>sauna</th>\n",
       "      <th>microwave</th>\n",
       "      <th>shares ok</th>\n",
       "      <th>post-war</th>\n",
       "      <th>brownstone</th>\n",
       "      <th>business center</th>\n",
       "      <th>sublet</th>\n",
       "      <th>midrise</th>\n",
       "      <th>pet friendly</th>\n",
       "      <th>guarantors accepted</th>\n",
       "      <th>attended lobby</th>\n",
       "      <th>package room</th>\n",
       "      <th>video intercom</th>\n",
       "      <th>community recreation facilities</th>\n",
       "      <th>skylight</th>\n",
       "      <th>flex-2</th>\n",
       "      <th>cable/satellite tv</th>\n",
       "      <th>all utilities included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.466755e+09</td>\n",
       "      <td>medium</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>3000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.465734e+09</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>5465</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  bathrooms  bedrooms       created interest_level  latitude  \\\n",
       "0     10        1.5         3  1.466755e+09         medium   40.7145   \n",
       "1  10000        1.0         2  1.465734e+09            low   40.7947   \n",
       "\n",
       "   listing_id  longitude  price  num_photos  elevator  hardwood floors  \\\n",
       "0     7211212   -73.9425   3000           5         0                0   \n",
       "1     7150865   -73.9667   5465          11         1                0   \n",
       "\n",
       "   doorman  dishwasher  laundry in building  no fee  fitness center  pre-war  \\\n",
       "0        0           0                    0       0               0        0   \n",
       "1        1           0                    0       0               1        0   \n",
       "\n",
       "   roof deck  outdoor space  dining room  high speed internet  balcony  \\\n",
       "0          0              0            0                    0        0   \n",
       "1          0              0            0                    0        0   \n",
       "\n",
       "   swimming pool  new construction  terrace  exclusive  loft  garden/patio  \\\n",
       "0              0                 0        0          0     0             0   \n",
       "1              0                 0        0          0     0             0   \n",
       "\n",
       "   wheelchair access  fireplace  simplex  lowrise  garage  reduced fee  \\\n",
       "0                  0          0        0        0       0            0   \n",
       "1                  0          0        0        0       0            0   \n",
       "\n",
       "   furnished  multi-level  high ceilings  private outdoor space  \\\n",
       "0          0            0              0                      0   \n",
       "1          0            0              0                      0   \n",
       "\n",
       "   parking space  live in super  renovated  green building  storage  \\\n",
       "0              0              0          0               0        1   \n",
       "1              0              0          0               0        0   \n",
       "\n",
       "   stainless steel appliances  light  granite kitchen  bike room  \\\n",
       "0                           0      0                0          0   \n",
       "1                           0      0                0          0   \n",
       "\n",
       "   exposed brick  marble bath  pets on approval  walk in closet(s)  valet  \\\n",
       "0              0            0                 0                  0      0   \n",
       "1              0            0                 0                  0      0   \n",
       "\n",
       "   subway  residents lounge  highrise  short term allowed  childrens playroom  \\\n",
       "0       0                 0         0                   0                   0   \n",
       "1       0                 0         0                   0                   0   \n",
       "\n",
       "   no pets  duplex  actual apt. photos  central a/c  view  live/work  \\\n",
       "0        0       0                   0            0     0          0   \n",
       "1        0       0                   0            0     0          0   \n",
       "\n",
       "   virtual doorman  sauna  microwave  shares ok  post-war  brownstone  \\\n",
       "0                0      0          0          0         0           0   \n",
       "1                0      0          0          0         0           0   \n",
       "\n",
       "   business center  sublet  midrise  pet friendly  guarantors accepted  \\\n",
       "0                0       0        0             0                    0   \n",
       "1                0       0        0             1                    0   \n",
       "\n",
       "   attended lobby  package room  video intercom  \\\n",
       "0               0             0               0   \n",
       "1               0             0               0   \n",
       "\n",
       "   community recreation facilities  skylight  flex-2  cable/satellite tv  \\\n",
       "0                                0         0       0                   0   \n",
       "1                                0         0       0                   0   \n",
       "\n",
       "   all utilities included  \n",
       "0                       0  \n",
       "1                       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(all_df.drop(['interest_level'], 1),all_df[['interest_level']], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_feats = cPickle.load(open('cat_feats.p', 'rb'))\n",
    "\n",
    "for col in ['interest_level']:\n",
    "    y_train[col] = y_train[col].astype('category')\n",
    "    y_val[col] = y_val[col].astype('category')\n",
    "    \n",
    "for col in cat_feats:\n",
    "    x_train[col] = x_train[col].astype('category')\n",
    "    x_val[col] = x_val[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_list = [u'listing_id', 'index']\n",
    "x_train_small = x_train.drop(drop_list,1)\n",
    "\n",
    "x_val_small = x_val.drop(drop_list,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39481, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low_pvalues_cols = cPickle.load(open('low_pvalues_cols.p', 'rb'))\n",
    "x_train_best = x_train_small#[low_pvalues_cols]\n",
    "x_val_best = x_val_small#[low_pvalues_cols]\n",
    "x_train_best.shape\n",
    "# x_train_best.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-86251590cc71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# n_estimator: 500; learning_rate: 0.2; max_features: 0.4; max_depth: 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=500, learning_rate=0.1, max_depth=4, max_features=0.3, random_state=0)\n",
    "# n_estimator: 500; learning_rate: 0.2; max_features: 0.4; max_depth: 3\n",
    "model = model.fit(x_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.918649</td>\n",
       "      <td>0.075486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.977797</td>\n",
       "      <td>0.021118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052934</td>\n",
       "      <td>0.585058</td>\n",
       "      <td>0.362009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051329</td>\n",
       "      <td>0.711687</td>\n",
       "      <td>0.236984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014158</td>\n",
       "      <td>0.906652</td>\n",
       "      <td>0.079190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       high       low    medium\n",
       "0  0.005865  0.918649  0.075486\n",
       "1  0.001084  0.977797  0.021118\n",
       "2  0.052934  0.585058  0.362009\n",
       "3  0.051329  0.711687  0.236984\n",
       "4  0.014158  0.906652  0.079190"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_train = pd.DataFrame(model.predict_proba(x_train_best))\n",
    "# predicted = model.predict_proba(x)\n",
    "predicted_train.columns = ['high', 'low', 'medium']\n",
    "predicted_train.head()\n",
    "# predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49517175136735192"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_train = log_loss(y_train, predicted_train.as_matrix())\n",
    "log_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068354</td>\n",
       "      <td>0.553789</td>\n",
       "      <td>0.377858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052149</td>\n",
       "      <td>0.663396</td>\n",
       "      <td>0.284455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.727591</td>\n",
       "      <td>0.237010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063397</td>\n",
       "      <td>0.674106</td>\n",
       "      <td>0.262497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.082843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       high       low    medium\n",
       "0  0.068354  0.553789  0.377858\n",
       "1  0.052149  0.663396  0.284455\n",
       "2  0.035400  0.727591  0.237010\n",
       "3  0.063397  0.674106  0.262497\n",
       "4  0.008215  0.908942  0.082843"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_val = pd.DataFrame(model.predict_proba(x_val_best))\n",
    "# predicted = model.predict_proba(x)\n",
    "predicted_val.columns = ['high', 'low', 'medium']\n",
    "predicted_val.head()\n",
    "# predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58950330718593591"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_val = log_loss(y_val, predicted_val.as_matrix())\n",
    "log_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = zip(x_train_best.columns, list(model.feature_importances_))\n",
    "a.sort(key = lambda t: t[1], reverse=True)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bad_feats_gb = [i[0] for i in a[-20:]]\n",
    "# cPickle.dump(bad_feats_gb, open('bad_feats_gb.p', 'wb')) \n",
    "bad_feats_gb = cPickle.load(open('bad_feats_gb.p', 'rb'))\n",
    "# bad_feats_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_best.drop(bad_feats_gb, axis=1, inplace=True)\n",
    "x_val_best.drop(bad_feats_gb, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39481, 60), (9871, 60))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_best.shape, x_val_best.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(log_loss, greater_is_better=False, needs_proba=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scoring=make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "log_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "              \"max_features\": ['sqrt',0.2, 0.3, 0.4, 0.5],\n",
    "              \"n_estimators\": [300, 400, 500, 600, 700, 800],\n",
    "              \"learning_rate\": [round(i,2) for i in np.arange(0.05,0.2,0.01)]\n",
    "             \"min_samples_split\": [None, 100, 300, 400, 500, 600, 800, 1000]\n",
    "             \"min_samples_leaf\": [None, 20, 40, 50, 70 ,100]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 100\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, n_jobs=-1, scoring=log_scoring, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 36.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2278.45 seconds for 50 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "search = random_search.fit(x_train_best, y_train['interest_level'])\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "# report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -0.60351, std: 0.00468, params: {'n_estimators': 100, 'max_features': 0.5, 'learning_rate': 0.4, 'max_depth': 3},\n",
       " mean: -0.60840, std: 0.00507, params: {'n_estimators': 500, 'max_features': 'sqrt', 'learning_rate': 0.4, 'max_depth': 3},\n",
       " mean: -0.60283, std: 0.00531, params: {'n_estimators': 300, 'max_features': 0.5, 'learning_rate': 0.3, 'max_depth': 2},\n",
       " mean: -0.66456, std: 0.00318, params: {'n_estimators': 100, 'max_features': 0.4, 'learning_rate': 0.2, 'max_depth': 1},\n",
       " mean: -0.62078, std: 0.00342, params: {'n_estimators': 100, 'max_features': 'sqrt', 'learning_rate': 0.2, 'max_depth': 4},\n",
       " mean: -0.61199, std: 0.00238, params: {'n_estimators': 100, 'max_features': 0.2, 'learning_rate': 0.3, 'max_depth': 3},\n",
       " mean: -0.62395, std: 0.00457, params: {'n_estimators': 100, 'max_features': 0.2, 'learning_rate': 0.2, 'max_depth': 3},\n",
       " mean: -0.59802, std: 0.00361, params: {'n_estimators': 300, 'max_features': 0.3, 'learning_rate': 0.3, 'max_depth': 3},\n",
       " mean: -0.64229, std: 0.00346, params: {'n_estimators': 300, 'max_features': 0.2, 'learning_rate': 0.2, 'max_depth': 1},\n",
       " mean: -0.64150, std: 0.00331, params: {'n_estimators': 500, 'max_features': 0.4, 'learning_rate': 0.1, 'max_depth': 1},\n",
       " mean: -0.63426, std: 0.00366, params: {'n_estimators': 100, 'max_features': 0.3, 'learning_rate': 0.2, 'max_depth': 2},\n",
       " mean: -0.61472, std: 0.00378, params: {'n_estimators': 100, 'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 4},\n",
       " mean: -0.60913, std: 0.00380, params: {'n_estimators': 300, 'max_features': 0.3, 'learning_rate': 0.2, 'max_depth': 2},\n",
       " mean: -0.60506, std: 0.00329, params: {'n_estimators': 500, 'max_features': 0.4, 'learning_rate': 0.6, 'max_depth': 2},\n",
       " mean: -0.70953, std: 0.00837, params: {'n_estimators': 500, 'max_features': 0.4, 'learning_rate': 0.6, 'max_depth': 4},\n",
       " mean: -0.61113, std: 0.00681, params: {'n_estimators': 300, 'max_features': 0.4, 'learning_rate': 0.3, 'max_depth': 4},\n",
       " mean: -0.68656, std: 0.00303, params: {'n_estimators': 100, 'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 1},\n",
       " mean: -0.59896, std: 0.00336, params: {'n_estimators': 500, 'max_features': 'sqrt', 'learning_rate': 0.2, 'max_depth': 3},\n",
       " mean: -0.59333, std: 0.00379, params: {'n_estimators': 500, 'max_features': 0.3, 'learning_rate': 0.1, 'max_depth': 4},\n",
       " mean: -0.61198, std: 0.00277, params: {'n_estimators': 300, 'max_features': 'sqrt', 'learning_rate': 0.6, 'max_depth': 3},\n",
       " mean: -0.65136, std: 0.00356, params: {'n_estimators': 100, 'max_features': 0.4, 'learning_rate': 0.1, 'max_depth': 2},\n",
       " mean: -0.60558, std: 0.00222, params: {'n_estimators': 300, 'max_features': 'sqrt', 'learning_rate': 0.4, 'max_depth': 3},\n",
       " mean: -0.61673, std: 0.00805, params: {'n_estimators': 100, 'max_features': 0.2, 'learning_rate': 0.6, 'max_depth': 4},\n",
       " mean: -0.62665, std: 0.00330, params: {'n_estimators': 500, 'max_features': 'sqrt', 'learning_rate': 0.4, 'max_depth': 1},\n",
       " mean: -0.60688, std: 0.00756, params: {'n_estimators': 300, 'max_features': 0.3, 'learning_rate': 0.4, 'max_depth': 3},\n",
       " mean: -0.60571, std: 0.00291, params: {'n_estimators': 300, 'max_features': 0.3, 'learning_rate': 0.1, 'max_depth': 3},\n",
       " mean: -0.63043, std: 0.00379, params: {'n_estimators': 100, 'max_features': 0.4, 'learning_rate': 0.1, 'max_depth': 3},\n",
       " mean: -0.64049, std: 0.00287, params: {'n_estimators': 100, 'max_features': 0.2, 'learning_rate': 0.2, 'max_depth': 2},\n",
       " mean: -0.65048, std: 0.00383, params: {'n_estimators': 300, 'max_features': 'sqrt', 'learning_rate': 0.2, 'max_depth': 1},\n",
       " mean: -0.69041, std: 0.00346, params: {'n_estimators': 100, 'max_features': 0.3, 'learning_rate': 0.1, 'max_depth': 1},\n",
       " mean: -0.62740, std: 0.00580, params: {'n_estimators': 500, 'max_features': 0.5, 'learning_rate': 0.3, 'max_depth': 1},\n",
       " mean: -0.63310, std: 0.00360, params: {'n_estimators': 100, 'max_features': 0.3, 'learning_rate': 0.1, 'max_depth': 3},\n",
       " mean: -0.62697, std: 0.00585, params: {'n_estimators': 100, 'max_features': 0.3, 'learning_rate': 0.3, 'max_depth': 2},\n",
       " mean: -0.62680, std: 0.00528, params: {'n_estimators': 500, 'max_features': 0.2, 'learning_rate': 0.3, 'max_depth': 1},\n",
       " mean: -0.61368, std: 0.00484, params: {'n_estimators': 500, 'max_features': 0.2, 'learning_rate': 0.3, 'max_depth': 4},\n",
       " mean: -0.60380, std: 0.00561, params: {'n_estimators': 100, 'max_features': 0.5, 'learning_rate': 0.4, 'max_depth': 4},\n",
       " mean: -0.63911, std: 0.00331, params: {'n_estimators': 500, 'max_features': 'sqrt', 'learning_rate': 0.2, 'max_depth': 1},\n",
       " mean: -0.82030, std: 0.25534, params: {'n_estimators': 500, 'max_features': 0.2, 'learning_rate': 0.6, 'max_depth': 4},\n",
       " mean: -0.60888, std: 0.00660, params: {'n_estimators': 300, 'max_features': 'sqrt', 'learning_rate': 0.6, 'max_depth': 2},\n",
       " mean: -0.62461, std: 0.00580, params: {'n_estimators': 500, 'max_features': 0.3, 'learning_rate': 0.4, 'max_depth': 1},\n",
       " mean: -0.61358, std: 0.00540, params: {'n_estimators': 500, 'max_features': 'sqrt', 'learning_rate': 0.2, 'max_depth': 2},\n",
       " mean: -0.63148, std: 0.00454, params: {'n_estimators': 100, 'max_features': 0.4, 'learning_rate': 0.2, 'max_depth': 2},\n",
       " mean: -0.60011, std: 0.00272, params: {'n_estimators': 500, 'max_features': 0.2, 'learning_rate': 0.1, 'max_depth': 3},\n",
       " mean: -0.61406, std: 0.00546, params: {'n_estimators': 300, 'max_features': 0.2, 'learning_rate': 0.6, 'max_depth': 3},\n",
       " mean: -0.60248, std: 0.00516, params: {'n_estimators': 300, 'max_features': 0.3, 'learning_rate': 0.6, 'max_depth': 2},\n",
       " mean: -0.60058, std: 0.00468, params: {'n_estimators': 300, 'max_features': 0.5, 'learning_rate': 0.4, 'max_depth': 2},\n",
       " mean: -0.60627, std: 0.00469, params: {'n_estimators': 500, 'max_features': 'sqrt', 'learning_rate': 0.3, 'max_depth': 2},\n",
       " mean: -0.61093, std: 0.00293, params: {'n_estimators': 100, 'max_features': 'sqrt', 'learning_rate': 0.4, 'max_depth': 4},\n",
       " mean: -0.60146, std: 0.00374, params: {'n_estimators': 500, 'max_features': 0.5, 'learning_rate': 0.2, 'max_depth': 2},\n",
       " mean: -0.65324, std: 0.00363, params: {'n_estimators': 300, 'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 1}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5933256136564423,\n",
       " GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=4,\n",
       "               max_features=0.3, max_leaf_nodes=None,\n",
       "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=500, presort='auto', random_state=None,\n",
       "               subsample=1.0, verbose=0, warm_start=False),\n",
       " {'learning_rate': 0.1,\n",
       "  'max_depth': 4,\n",
       "  'max_features': 0.3,\n",
       "  'n_estimators': 500})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_, search.best_estimator_, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39481, 60), (39481, 1))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_best.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RandomizedSearchCV in module sklearn.grid_search object:\n",
      "\n",
      "class RandomizedSearchCV(BaseSearchCV)\n",
      " |  Randomized search on hyper parameters.\n",
      " |  \n",
      " |  .. deprecated:: 0.18\n",
      " |      This module will be removed in 0.20.\n",
      " |      Use :class:`sklearn.model_selection.RandomizedSearchCV` instead.\n",
      " |  \n",
      " |  RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated search over parameter settings.\n",
      " |  \n",
      " |  In contrast to GridSearchCV, not all parameter values are tried out, but\n",
      " |  rather a fixed number of parameter settings is sampled from the specified\n",
      " |  distributions. The number of parameter settings that are tried is\n",
      " |  given by n_iter.\n",
      " |  \n",
      " |  If all parameters are presented as a list,\n",
      " |  sampling without replacement is performed. If at least one parameter\n",
      " |  is given as a distribution, sampling with replacement is used.\n",
      " |  It is highly recommended to use continuous distributions for continuous\n",
      " |  parameters.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      A object of that type is instantiated for each grid point.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_distributions : dict\n",
      " |      Dictionary with parameters names (string) as keys and distributions\n",
      " |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      " |      method for sampling (such as those from scipy.stats.distributions).\n",
      " |      If a list is given, it is sampled uniformly.\n",
      " |  \n",
      " |  n_iter : int, default=10\n",
      " |      Number of parameter settings that are sampled. n_iter trades\n",
      " |      off runtime vs quality of the solution.\n",
      " |  \n",
      " |  scoring : string, callable or None, default=None\n",
      " |      A string (see model evaluation documentation) or\n",
      " |      a scorer callable object / function with signature\n",
      " |      ``scorer(estimator, X, y)``.\n",
      " |      If ``None``, the ``score`` method of the estimator is used.\n",
      " |  \n",
      " |  fit_params : dict, optional\n",
      " |      Parameters to pass to the fit method.\n",
      " |  \n",
      " |  n_jobs : int, default=1\n",
      " |      Number of jobs to run in parallel.\n",
      " |  \n",
      " |  pre_dispatch : int, or string, optional\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A string, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : boolean, default=True\n",
      " |      If True, the data is assumed to be identically distributed across\n",
      " |      the folds, and the loss minimized is the total loss per sample,\n",
      " |      and not the mean loss across the folds.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, optional\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 3-fold cross-validation,\n",
      " |      - integer, to specify the number of folds.\n",
      " |      - An object to be used as a cross-validation generator.\n",
      " |      - An iterable yielding train/test splits.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, \n",
      " |      :class:`sklearn.model_selection.StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`sklearn.model_selection.KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |  refit : boolean, default=True\n",
      " |      Refit the best estimator with the entire dataset.\n",
      " |      If \"False\", it is impossible to make predictions using\n",
      " |      this RandomizedSearchCV instance after fitting.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  random_state : int or RandomState\n",
      " |      Pseudo random number generator state used for random uniform sampling\n",
      " |      from lists of possible values instead of scipy.stats distributions.\n",
      " |  \n",
      " |  error_score : 'raise' (default) or numeric\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  grid_scores_ : list of named tuples\n",
      " |      Contains scores for all parameter combinations in param_grid.\n",
      " |      Each entry corresponds to one parameter setting.\n",
      " |      Each named tuple has the attributes:\n",
      " |  \n",
      " |          * ``parameters``, a dict of parameter settings\n",
      " |          * ``mean_validation_score``, the mean score over the\n",
      " |            cross-validation folds\n",
      " |          * ``cv_validation_scores``, the list of scores for each fold\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if refit=False.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Score of best_estimator on the left out data.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the held-out\n",
      " |  data, according to the scoring parameter.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  parameter setting(and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  :class:`GridSearchCV`:\n",
      " |      Does exhaustive search over a grid of parameters.\n",
      " |  \n",
      " |  :class:`ParameterSampler`:\n",
      " |      A generator over parameter settings, constructed from\n",
      " |      param_distributions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomizedSearchCV\n",
      " |      BaseSearchCV\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_distributions, n_iter=10, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score='raise')\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Run fit on the estimator with randomly drawn parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Training vector, where n_samples in the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(*args, **kwargs)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  inverse_transform(*args, **kwargs)\n",
      " |      Call inverse_transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements ``inverse_transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(*args, **kwargs)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(*args, **kwargs)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(*args, **kwargs)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |       * The long-standing behavior of this method changed in version 0.16.\n",
      " |       * It no longer uses the metric provided by ``estimator.score`` if the\n",
      " |         ``scoring`` parameter was set when fitting.\n",
      " |  \n",
      " |  transform(*args, **kwargs)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cv_loss(ne, lr, md, mf):\n",
    "    kf = KFold(x_train_best.shape[0], n_folds=5, random_state=2017)\n",
    "    loss_tr = []\n",
    "    loss_ts = []\n",
    "    for train_index, test_index in kf:\n",
    "        x_tr = x_train_best.reset_index().loc[train_index].set_index(['index'])\n",
    "        y_tr =  y_train.reset_index().loc[train_index].set_index(['index'])\n",
    "        x_ts = x_train_best.reset_index().loc[test_index].set_index(['index'])\n",
    "        y_ts = y_train.reset_index().loc[test_index].set_index(['index'])\n",
    "\n",
    "        model = GradientBoostingClassifier(n_estimators=ne, learning_rate=lr, max_depth=md, max_features=mf, random_state=20)\n",
    "\n",
    "        model = model.fit(x_tr, y_tr)\n",
    "\n",
    "        predicted_ts = pd.DataFrame(model.predict_proba(x_ts))\n",
    "        predicted_ts.columns = ['high', 'low', 'medium']\n",
    "        log_loss_ts = log_loss(y_ts, predicted_ts.as_matrix())\n",
    "        loss_ts.append(log_loss_ts)\n",
    "    \n",
    "    print 'CV loss:', np.mean(loss_ts)\n",
    "    predicted_val = pd.DataFrame(model.predict_proba(x_val_best))\n",
    "    predicted_val.columns = ['high', 'low', 'medium']\n",
    "    log_loss_val = log_loss(y_val, predicted_val.as_matrix())\n",
    "    print 'Val loss:', log_loss_val\n",
    "    return np.mean(loss_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "n_estimator: 500; learning_rate: 0.4; max_features: sqrt; max_depth: 1\n",
      "CV loss: 0.625799776246\n",
      "Val loss: 0.628988463414\n",
      "51\n",
      "n_estimator: 500; learning_rate: 0.4; max_features: 0.2; max_depth: 1\n",
      "CV loss: 0.624416750049\n",
      "Val loss: 0.622868663987\n",
      "52\n",
      "n_estimator: 500; learning_rate: 0.4; max_features: 0.4; max_depth: 1\n",
      "CV loss: 0.624925251005\n",
      "Val loss: 0.620767325559\n",
      "53\n",
      "n_estimator: 500; learning_rate: 0.4; max_features: 0.8; max_depth: 1\n",
      "CV loss: 0.626268963256\n",
      "Val loss: 0.620891598599\n",
      "54\n",
      "n_estimator: 500; learning_rate: 0.4; max_features: sqrt; max_depth: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-81e4619cd2a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#                 best_loss = log_loss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#                 best_params = params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mcv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cv_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcv_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-5b5d200f7b71>\u001b[0m in \u001b[0;36mget_cv_loss\u001b[0;34m(ne, lr, md, mf)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpredicted_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             residual = loss.negative_gradient(y, y_pred, k=k,\n\u001b[0;32m--> 763\u001b[0;31m                                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;31m# induce regression tree on residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, pred, k, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;34m\"\"\"Compute negative gradient for the ``k``-th class. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         return y - np.nan_to_num(np.exp(pred[:, k] -\n\u001b[0;32m--> 564\u001b[0;31m                                         logsumexp(pred, axis=1)))\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;31m# Use the max to normalize, as with the log this is what accumulates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;31m# the less errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamirlan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_estimators = [500]\n",
    "learning_rates = [0.4, 0.6, 0.8, 1]\n",
    "max_features = ['sqrt',0.2, 0.4, 0.8]\n",
    "max_depth = [1, 3, 5]#, 12, 14, 16, 18, 20]\n",
    "best_loss = 100\n",
    "best_params = ''\n",
    "count = 50\n",
    "for ne in n_estimators:\n",
    "    for lr in learning_rates:\n",
    "        for md in max_depth:\n",
    "            for mf in max_features:\n",
    "                print count\n",
    "                count += 1\n",
    "                params = 'n_estimator: ' + str(ne) + '; learning_rate: ' + str(lr) + '; max_features: ' + str(mf) + '; max_depth: ' + str(md)\n",
    "                print params\n",
    "    #             model = RandomForestClassifier(n_estimators=500, max_features=mf, max_depth=md, min_samples_split=mss, random_state=0)\n",
    "    #             model = model.fit(x_train_best, y_train)\n",
    "    #             predicted_train = pd.DataFrame(model.predict_proba(x_train_best))\n",
    "    #             predicted_train.columns = ['high', 'low', 'medium']\n",
    "    #             log_loss_train = log_loss(y_train, predicted_train.as_matrix())\n",
    "    #             print 'Train loss:', log_loss_train\n",
    "    #             predicted_val = pd.DataFrame(model.predict_proba(x_val_best))\n",
    "    #             predicted_val.columns = ['high', 'low', 'medium']\n",
    "    #             log_loss_val = log_loss(y_val, predicted_val.as_matrix())\n",
    "    #             print 'Val loss:', log_loss_val\n",
    "    #             if log_loss_val < best_loss:\n",
    "    #                 best_loss = log_loss_val\n",
    "    #                 best_params = params\n",
    "                cv_loss = get_cv_loss(ne, lr, md, mf)\n",
    "                if cv_loss < best_loss:\n",
    "                    best_loss = cv_loss\n",
    "                    best_params = params   \n",
    "\n",
    "print 'best_loss:', best_loss\n",
    "print 'best_params:', best_params\n",
    "# best_loss: 0.638016960424\n",
    "# best_params: max_features: 0.3; max_depth: 18; min_samples_split: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "## Competition Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_feats_max_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>created</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>elevator</th>\n",
       "      <th>hardwood floors</th>\n",
       "      <th>doorman</th>\n",
       "      <th>dishwasher</th>\n",
       "      <th>laundry in building</th>\n",
       "      <th>no fee</th>\n",
       "      <th>fitness center</th>\n",
       "      <th>pre-war</th>\n",
       "      <th>roof deck</th>\n",
       "      <th>outdoor space</th>\n",
       "      <th>dining room</th>\n",
       "      <th>high speed internet</th>\n",
       "      <th>balcony</th>\n",
       "      <th>swimming pool</th>\n",
       "      <th>new construction</th>\n",
       "      <th>terrace</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>loft</th>\n",
       "      <th>garden/patio</th>\n",
       "      <th>wheelchair access</th>\n",
       "      <th>fireplace</th>\n",
       "      <th>simplex</th>\n",
       "      <th>lowrise</th>\n",
       "      <th>garage</th>\n",
       "      <th>reduced fee</th>\n",
       "      <th>furnished</th>\n",
       "      <th>multi-level</th>\n",
       "      <th>high ceilings</th>\n",
       "      <th>private outdoor space</th>\n",
       "      <th>parking space</th>\n",
       "      <th>live in super</th>\n",
       "      <th>renovated</th>\n",
       "      <th>green building</th>\n",
       "      <th>storage</th>\n",
       "      <th>stainless steel appliances</th>\n",
       "      <th>light</th>\n",
       "      <th>granite kitchen</th>\n",
       "      <th>bike room</th>\n",
       "      <th>exposed brick</th>\n",
       "      <th>marble bath</th>\n",
       "      <th>pets on approval</th>\n",
       "      <th>walk in closet(s)</th>\n",
       "      <th>valet</th>\n",
       "      <th>subway</th>\n",
       "      <th>residents lounge</th>\n",
       "      <th>highrise</th>\n",
       "      <th>short term allowed</th>\n",
       "      <th>childrens playroom</th>\n",
       "      <th>no pets</th>\n",
       "      <th>duplex</th>\n",
       "      <th>actual apt. photos</th>\n",
       "      <th>central a/c</th>\n",
       "      <th>view</th>\n",
       "      <th>live/work</th>\n",
       "      <th>virtual doorman</th>\n",
       "      <th>sauna</th>\n",
       "      <th>microwave</th>\n",
       "      <th>shares ok</th>\n",
       "      <th>post-war</th>\n",
       "      <th>brownstone</th>\n",
       "      <th>business center</th>\n",
       "      <th>sublet</th>\n",
       "      <th>midrise</th>\n",
       "      <th>pet friendly</th>\n",
       "      <th>guarantors accepted</th>\n",
       "      <th>attended lobby</th>\n",
       "      <th>package room</th>\n",
       "      <th>video intercom</th>\n",
       "      <th>community recreation facilities</th>\n",
       "      <th>skylight</th>\n",
       "      <th>flex-2</th>\n",
       "      <th>cable/satellite tv</th>\n",
       "      <th>all utilities included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.465623e+09</td>\n",
       "      <td>40.7185</td>\n",
       "      <td>7142618</td>\n",
       "      <td>-73.9865</td>\n",
       "      <td>2950</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.466750e+09</td>\n",
       "      <td>40.7278</td>\n",
       "      <td>7210040</td>\n",
       "      <td>-74.0000</td>\n",
       "      <td>2850</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  bathrooms  bedrooms       created  latitude  listing_id  longitude  \\\n",
       "0      0        1.0         1  1.465623e+09   40.7185     7142618   -73.9865   \n",
       "1      1        1.0         2  1.466750e+09   40.7278     7210040   -74.0000   \n",
       "\n",
       "   price  num_photos  elevator  hardwood floors  doorman  dishwasher  \\\n",
       "0   2950           8         1                1        0           1   \n",
       "1   2850           3         0                1        0           0   \n",
       "\n",
       "   laundry in building  no fee  fitness center  pre-war  roof deck  \\\n",
       "0                    1       0               0        0          0   \n",
       "1                    0       0               0        1          0   \n",
       "\n",
       "   outdoor space  dining room  high speed internet  balcony  swimming pool  \\\n",
       "0              1            0                    0        0              0   \n",
       "1              0            0                    0        0              0   \n",
       "\n",
       "   new construction  terrace  exclusive  loft  garden/patio  \\\n",
       "0                 0        1          0     0             0   \n",
       "1                 0        0          0     0             0   \n",
       "\n",
       "   wheelchair access  fireplace  simplex  lowrise  garage  reduced fee  \\\n",
       "0                  0          0        0        0       0            0   \n",
       "1                  0          0        0        0       0            0   \n",
       "\n",
       "   furnished  multi-level  high ceilings  private outdoor space  \\\n",
       "0          0            0              0                      0   \n",
       "1          0            0              0                      0   \n",
       "\n",
       "   parking space  live in super  renovated  green building  storage  \\\n",
       "0              0              0          1               0        1   \n",
       "1              0              0          1               0        0   \n",
       "\n",
       "   stainless steel appliances  light  granite kitchen  bike room  \\\n",
       "0                           0      0                0          0   \n",
       "1                           1      0                0          0   \n",
       "\n",
       "   exposed brick  marble bath  pets on approval  walk in closet(s)  valet  \\\n",
       "0              0            0                 0                  0      0   \n",
       "1              0            1                 0                  0      0   \n",
       "\n",
       "   subway  residents lounge  highrise  short term allowed  childrens playroom  \\\n",
       "0       1                 0         0                   0                   0   \n",
       "1       0                 0         0                   0                   0   \n",
       "\n",
       "   no pets  duplex  actual apt. photos  central a/c  view  live/work  \\\n",
       "0        0       0                   0            0     0          0   \n",
       "1        0       0                   0            0     1          0   \n",
       "\n",
       "   virtual doorman  sauna  microwave  shares ok  post-war  brownstone  \\\n",
       "0                0      0          0          0         0           0   \n",
       "1                0      0          0          0         0           0   \n",
       "\n",
       "   business center  sublet  midrise  pet friendly  guarantors accepted  \\\n",
       "0                0       0        0             0                    0   \n",
       "1                0       0        0             1                    0   \n",
       "\n",
       "   attended lobby  package room  video intercom  \\\n",
       "0               0             0               0   \n",
       "1               0             0               0   \n",
       "\n",
       "   community recreation facilities  skylight  flex-2  cable/satellite tv  \\\n",
       "0                                0         0       0                   0   \n",
       "1                                0         0       0                   0   \n",
       "\n",
       "   all utilities included  \n",
       "0                       0  \n",
       "1                       0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 60)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test_df[x_train_best.columns]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048373</td>\n",
       "      <td>0.618934</td>\n",
       "      <td>0.332693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.159526</td>\n",
       "      <td>0.427932</td>\n",
       "      <td>0.412542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024810</td>\n",
       "      <td>0.853985</td>\n",
       "      <td>0.121205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029124</td>\n",
       "      <td>0.641466</td>\n",
       "      <td>0.329410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.890598</td>\n",
       "      <td>0.099354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       high       low    medium\n",
       "0  0.048373  0.618934  0.332693\n",
       "1  0.159526  0.427932  0.412542\n",
       "2  0.024810  0.853985  0.121205\n",
       "3  0.029124  0.641466  0.329410\n",
       "4  0.010049  0.890598  0.099354"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_x = pd.DataFrame(model.predict_proba(x_test))\n",
    "pred_x.columns = ['high', 'low', 'medium']\n",
    "pred_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm = pd.merge(test_df[['listing_id']].reset_index(), pred_x.reset_index(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = subm[['listing_id', 'high', 'medium', 'low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.shape\n",
    "# (74659, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm.to_csv('Submission_GB_auto_tune2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=3,\n",
       "              max_features=0.4, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=500, presort='auto', random_state=0,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
